{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "295d62e1",
   "metadata": {},
   "source": [
    "# Stack Overflow Survey Trends\n",
    "\n",
    "**Understanding developer trends in Stack Overflow survey data**\n",
    "\n",
    "This is an Off-Platform Project provided by Codecademy's Data Science: Analyst career track in the *Handling Missing Data* course, inside of the *Data Wrangling, Cleaning, and Tidying* Unit.\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "You work for a staffing agency that specializes in finding qualified candidates for development roles. One of your latest clients is growing rapidly and wants to understand what kinds of developers they can hire, and to understand general trends of the technology market. Your organization has access to this [Stack Overflow dataset](https://static-assets.codecademy.com/Courses/handling-missing-data/stackoverflow-project/developer_dataset.csv.zip?_gl=1*lbwq7o*_ga*NDE0MTMwODY3OC4xNjkxNjI5Mzc4*_ga_3LRZM6TM9L*MTcwODM4ODY5My4yMTYuMS4xNzA4Mzg5MjM1LjUzLjAuMA..), which consists of survey responses by developers all over the world for the last few years.\n",
    "\n",
    "Your project is to put together several statistical analyses about the community to educate your client about the potential hiring market for their company.\n",
    "\n",
    "## Project Steps\n",
    "\n",
    "### Explore Data\n",
    "\n",
    "You decide to start by performing some **Exploratory Data Analysis (EDA)**. This will provide you with a high-level understanding of the data fields, as well as help you identify which columns have missing data. In this case, you load the dataset into a `pandas` DataFrame and call it `df`. Take a moment to explore which columns you have in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ba84c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['RespondentID', 'Year', 'Country', 'Employment', 'UndergradMajor',\n",
      "       'DevType', 'LanguageWorkedWith', 'LanguageDesireNextYear',\n",
      "       'DatabaseWorkedWith', 'DatabaseDesireNextYear', 'PlatformWorkedWith',\n",
      "       'PlatformDesireNextYear', 'Hobbyist', 'OrgSize', 'YearsCodePro',\n",
      "       'JobSeek', 'ConvertedComp', 'WorkWeekHrs', 'NEWJobHunt',\n",
      "       'NEWJobHuntResearch', 'NEWLearn'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dz/csjpb9qj4dqf_c5tnq_cjz8c0000gn/T/ipykernel_69315/787547253.py:4: DtypeWarning: Columns (18,19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('developer_dataset.csv')\n"
     ]
    }
   ],
   "source": [
    "# Import the pandas library to read csv files\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('developer_dataset.csv')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf13032",
   "metadata": {},
   "source": [
    "We notice that the `RespondentID`, `Year`, and `Country` can be used to identify a person in our data.\n",
    "\n",
    "Their experiences can be found via `LanguageWorkedWith`, `DatabaseWorkedWith`, `UndergradMajor`.\n",
    "\n",
    "Information about what they might want to do in the future are contained in `LanguagedDesireNextYear`, `DatabaseDesireNextYear`, \n",
    "\n",
    "We will now inspect the NaN values of the dataset. Note that the survey questions were optional, so we can expect that we will have significant NaN values throughout the dataset. We will use `df.count()` to see where we are seeing NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8164986e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RespondentID              111209\n",
       "Year                      111209\n",
       "Country                   111209\n",
       "Employment                109425\n",
       "UndergradMajor             98453\n",
       "DevType                   100433\n",
       "LanguageWorkedWith        102018\n",
       "LanguageDesireNextYear     96044\n",
       "DatabaseWorkedWith         85859\n",
       "DatabaseDesireNextYear     74234\n",
       "PlatformWorkedWith         91609\n",
       "PlatformDesireNextYear     85376\n",
       "Hobbyist                   68352\n",
       "OrgSize                    54804\n",
       "YearsCodePro               94793\n",
       "JobSeek                    60556\n",
       "ConvertedComp              91333\n",
       "WorkWeekHrs                51089\n",
       "NEWJobHunt                 19127\n",
       "NEWJobHuntResearch         18683\n",
       "NEWLearn                   24226\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the total counts for each of the columns\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ea34c1",
   "metadata": {},
   "source": [
    "We will perform some basic summary statistics on the dataset to understand the \n",
    "- average values\n",
    "- max values\n",
    "- min values\n",
    "- the number of missing data points\n",
    "for our numerical columns. We will use the `.describe()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97deb296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RespondentID</th>\n",
       "      <th>Year</th>\n",
       "      <th>YearsCodePro</th>\n",
       "      <th>ConvertedComp</th>\n",
       "      <th>WorkWeekHrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>111209.0</td>\n",
       "      <td>111209.0</td>\n",
       "      <td>94793.0</td>\n",
       "      <td>91333.0</td>\n",
       "      <td>51089.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19262.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>125178.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11767.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>246122.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9268.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>46000.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18535.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>28347.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42857.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>475.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RespondentID      Year  YearsCodePro  ConvertedComp  WorkWeekHrs\n",
       "count      111209.0  111209.0       94793.0        91333.0      51089.0\n",
       "mean        19262.0    2019.0          10.0       125178.0         41.0\n",
       "std         11767.0       1.0           8.0       246122.0         14.0\n",
       "min             1.0    2018.0           0.0            0.0          1.0\n",
       "25%          9268.0    2018.0           4.0        46000.0         40.0\n",
       "50%         18535.0    2019.0           8.0        79000.0         40.0\n",
       "75%         28347.0    2019.0          14.0       120000.0         42.0\n",
       "max         42857.0    2020.0          50.0      2000000.0        475.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Provide the summary statistics\n",
    "df.describe().round()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b0ab39",
   "metadata": {},
   "source": [
    "The summary statistics shown above desribe the center and spread of our quantitative variables. \n",
    "\n",
    "The `YearsCodePro` and `ConvertedComp` have some missing values. `ConvertedComp` also has a seemingly high standard deviation with **246122.0**. We might need to inspect this variable further to see why the spread is high. It could be due to outlier compensation values, especially when the median value is very small compared to the maximum value.\n",
    "\n",
    "It seems that the `WorkWeekHrs` has a significant number of NaN values. In addition, it has a max value of **475.0** hours; which would mean that the person worked about 20 hours a day. This could mean that some of the datapoints are erroneously inputted, and that there may be additional mistakes throughout the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8996fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
